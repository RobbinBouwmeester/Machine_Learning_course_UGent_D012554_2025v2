{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdgroeve/Machine_Learning_course_UGent_D012554_2025/blob/main/notebooks/data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M5B6XEim8LF"
      },
      "source": [
        "# Data Preprocessing for Machine Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMdNcp8pm8LG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Set the style for our visualizations\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"deep\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjkaxLkNm8LH"
      },
      "source": [
        "## Loading a Dataset\n",
        "\n",
        "The breast cancer dataset is a classic dataset in machine learning. It contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. These features describe characteristics of the cell nuclei present in the image.\n",
        "\n",
        "The dataset includes 569 instances with 30 features each. The target variable indicates whether the cancer is malignant (0) or benign (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeGPX5lWm8LH"
      },
      "outputs": [],
      "source": [
        "cancer = datasets.load_breast_cancer()\n",
        "print(f\"Features: {cancer.feature_names}\")\n",
        "print(f\"Target: {cancer.target_names}\")\n",
        "print(f\"Dataset shape: {cancer.data.shape}\")\n",
        "\n",
        "# Convert to pandas DataFrame for easier manipulation\n",
        "df = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
        "df['target'] = cancer.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBL0j7lZm8LH"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhtJ4arvm8LI"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw_msusjm8LI"
      },
      "outputs": [],
      "source": [
        "df.describe().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtM5Hkp2m8LI"
      },
      "outputs": [],
      "source": [
        "df.boxplot(vert= False, figsize=(12, 6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_iO-ZVOdm8LI"
      },
      "outputs": [],
      "source": [
        "# Let's create a function to visualize the distribution of a feature\n",
        "def plot_feature_distribution(feature_name):\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.histplot(df[df['target'] == 0][feature_name], color='red', label='Malignant', kde=True)\n",
        "    sns.histplot(df[df['target'] == 1][feature_name], color='blue', label='Benign', kde=True)\n",
        "    plt.title(f'Distribution of {feature_name} by Target Class')\n",
        "    plt.xlabel(feature_name)\n",
        "    plt.ylabel('Count')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(x='target', y=feature_name, data=df)\n",
        "    plt.title(f'Boxplot of {feature_name} by Target Class')\n",
        "    plt.xticks([0, 1], ['Malignant', 'Benign'])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize one of the features\n",
        "plot_feature_distribution('mean radius')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RiCl_l0Fm8LI"
      },
      "source": [
        "## Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vn8Y5uGVm8LI"
      },
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(f\"Training set shape: {X_train.shape}\")\n",
        "print(f\"Testing set shape: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbNHXTn2m8LJ"
      },
      "source": [
        "## Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hPMt5xmm8LJ"
      },
      "source": [
        "### StandardScaler (Z-score normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IskSSFlgm8LJ"
      },
      "outputs": [],
      "source": [
        "print(\"Before scaling (first 5 rows, first 5 features):\")\n",
        "print(X_train.iloc[:5, :5])\n",
        "\n",
        "# Standardization (z-score normalization)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame for easier viewing\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
        "print(\"\\nAfter StandardScaler (first 5 rows, first 5 features):\")\n",
        "print(X_train_scaled_df.iloc[:5, :5])\n",
        "\n",
        "print(\"\\nMean and standard deviation of 'mean radius' after scaling:\")\n",
        "print(f\"Mean: {X_train_scaled_df['mean radius'].mean():.6f}\")\n",
        "print(f\"Std: {X_train_scaled_df['mean radius'].std():.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DISFyzo3m8LJ"
      },
      "outputs": [],
      "source": [
        "# Visualize the effect of standardization\n",
        "feature = 'mean radius'\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(X_train[feature], kde=True)\n",
        "plt.title(f'Distribution of {feature} (Before Scaling)')\n",
        "plt.xlabel(feature)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(X_train_scaled_df[feature], kde=True)\n",
        "plt.title(f'Distribution of {feature} (After StandardScaler)')\n",
        "plt.xlabel(f'{feature} (scaled)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qosyr9Ntm8LJ"
      },
      "source": [
        "### MinMaxScaler (0-1 normalization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wy_J3UBlm8LJ"
      },
      "outputs": [],
      "source": [
        "# Min-Max scaling\n",
        "min_max_scaler = MinMaxScaler()\n",
        "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
        "X_test_minmax = min_max_scaler.transform(X_test)\n",
        "\n",
        "# Convert back to DataFrame\n",
        "X_train_minmax_df = pd.DataFrame(X_train_minmax, columns=X_train.columns)\n",
        "print(\"After MinMaxScaler (first 5 rows, first 5 features):\")\n",
        "print(X_train_minmax_df.iloc[:5, :5])\n",
        "\n",
        "print(\"\\nMin and max of 'mean radius' after scaling:\")\n",
        "print(f\"Min: {X_train_minmax_df['mean radius'].min():.6f}\")\n",
        "print(f\"Max: {X_train_minmax_df['mean radius'].max():.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3OZ5ssSm8LJ"
      },
      "outputs": [],
      "source": [
        "# Visualize the effect of min-max scaling\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(X_train[feature], kde=True)\n",
        "plt.title(f'Distribution of {feature} (Before Scaling)')\n",
        "plt.xlabel(feature)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.histplot(X_train_minmax_df[feature], kde=True)\n",
        "plt.title(f'Distribution of {feature} (After MinMaxScaler)')\n",
        "plt.xlabel(f'{feature} (scaled)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaQd9ySIm8LJ"
      },
      "source": [
        "## Working with Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1x5pi2Ykm8LJ"
      },
      "outputs": [],
      "source": [
        "# For demonstration, let's create a categorical feature\n",
        "np.random.seed(42)\n",
        "categories = ['A+', 'A-', 'B+', 'B-', 'O+', 'O-', 'AB+', 'AB-']\n",
        "df['category'] = np.random.choice(categories, size=df.shape[0])\n",
        "\n",
        "print(\"\\nAdded a synthetic categorical feature:\")\n",
        "print(df[['category', 'target']].head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiJREihSm8LJ"
      },
      "source": [
        "### 5.1 One-Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMUslnx8m8LJ"
      },
      "outputs": [],
      "source": [
        "# One-hot encoding with sklearn\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "encoded = encoder.fit_transform(df[['category']])\n",
        "\n",
        "# Get the feature names\n",
        "encoded_feature_names = encoder.get_feature_names_out(['category'])\n",
        "print(f\"Encoded feature names: {encoded_feature_names}\")\n",
        "\n",
        "# Create a DataFrame with encoded features\n",
        "encoded_df = pd.DataFrame(encoded, columns=encoded_feature_names)\n",
        "print(\"\\nOne-hot encoded features (first 10 rows):\")\n",
        "print(encoded_df.head(10))\n",
        "\n",
        "print(\"\\nOriginal categorical data vs. encoded data:\")\n",
        "comparison = pd.concat([df[['category']].reset_index(drop=True),\n",
        "                         encoded_df.reset_index(drop=True)], axis=1)\n",
        "print(comparison.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5E_EFsSm8LK"
      },
      "source": [
        "## Creating a Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xC9I0cJ-m8LK"
      },
      "outputs": [],
      "source": [
        "# Define which columns are numerical and which are categorical\n",
        "numerical_features = cancer.feature_names\n",
        "categorical_features = ['category']\n",
        "\n",
        "# Create transformers for each type of feature\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(drop='first'))\n",
        "])\n",
        "\n",
        "# Combine transformers using ColumnTransformer\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Create the full dataset with the categorical feature\n",
        "X_with_cat = df.drop('target', axis=1)\n",
        "y = df['target']\n",
        "\n",
        "# Split the data\n",
        "X_train_with_cat, X_test_with_cat, y_train, y_test = train_test_split(\n",
        "    X_with_cat, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "# Apply the preprocessing pipeline\n",
        "X_train_processed = preprocessor.fit_transform(X_train_with_cat)\n",
        "X_test_processed = preprocessor.transform(X_test_with_cat)\n",
        "\n",
        "print(f\"Shape before preprocessing: {X_train_with_cat.shape}\")\n",
        "print(f\"Shape after preprocessing: {X_train_processed.shape}\")\n",
        "\n",
        "# Get the feature names after transformation\n",
        "numerical_feature_names = numerical_features\n",
        "categorical_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
        "all_feature_names = list(numerical_feature_names) + list(categorical_feature_names)\n",
        "\n",
        "print(f\"\\nFeature names after preprocessing: {all_feature_names[:5]} ... {all_feature_names[-2:]} (total: {len(all_feature_names)})\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}